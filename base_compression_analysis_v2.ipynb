{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Loading OpenAI API key\n",
    "ENV_FILE_PATH = \".env\"\n",
    "load_dotenv(ENV_FILE_PATH, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "import zlib\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import concurrent.futures as cf\n",
    "import itertools\n",
    "\n",
    "import utils.functions as functions\n",
    "from utils.openai_handler import OpenAIHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring that the OpenAI API key is set\n",
    "OpenAIHandler.set_api_key(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Setting up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LITERARY_TEXT_DIR = 'text_data/literary'\n",
    "file_name_to_original_text: Dict[str, str] = {}\n",
    "for f_name in os.listdir(LITERARY_TEXT_DIR):\n",
    "    if not f_name.endswith('.txt'):\n",
    "        logging.warning(f'File {f_name} is not a text file. Skipping.')\n",
    "        continue\n",
    "    with open(f'{LITERARY_TEXT_DIR}/{f_name}', 'r') as f:\n",
    "        file_name_to_original_text[f_name] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Base Compression Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_compression_system_prompt = \"\"\" \n",
    "You are LLM text compression system. Given inputted text, compress it into the smallest possible character representation.\n",
    "You should compress the text into a latent space representation, that only needs to be able to be reconstructed with a different {model_type}.\n",
    "Do not simply abbreviate words or remove spaces and do not use any compression algorithms. \n",
    "Return only the compressed text as a string. \"\"\"\n",
    "\n",
    "base_compression_user_prompt = base_compression_system_prompt + \\\n",
    "\"\"\"\n",
    "### Text To Compress ###\n",
    "{original_text}\n",
    "\"\"\"\n",
    "\n",
    "base_decompression_system_prompt = \"\"\" \n",
    "You are LLM text decompression system. Given inputted text, decompress it into its original form.\n",
    "A different {model_type} has compressed the text into a latent space representation such that it can be reconstructed by you.\n",
    "Do not simply abbreviate words or remove spaces and do not use any decompression algorithms.\n",
    "Return only the decompressed text as a string. \"\"\"\n",
    "\n",
    "base_decompression_user_prompt = base_decompression_system_prompt + \\\n",
    "\"\"\"\n",
    "### Text To Decompress ###\n",
    "{compressed_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_35_MODEL = 'gpt-3.5-turbo'\n",
    "GPT_4_MODEL = 'gpt-4'\n",
    "GPT_4_TURBO_MODEL = 'gpt-4-1106-preview'\n",
    "\n",
    "MODEL_TYPES = [GPT_35_MODEL, GPT_4_MODEL, GPT_4_TURBO_MODEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(original_text: str, model_type: str, system_prompt: str, user_prompt: str) -> str:\n",
    "    system_prompt = system_prompt.format(model_type=model_type)\n",
    "    user_prompt = user_prompt.format(original_text=original_text, model_type=model_type)\n",
    "    compression_messages = [\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': user_prompt}]\n",
    "    return OpenAIHandler.get_chat_completion(compression_messages, model=model_type)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREADS = 10\n",
    "\n",
    "model_to_compressed_text: Dict[str, Dict[str, str]] = defaultdict(dict)\n",
    "compression_func_args = [\n",
    "    (file_name, text, model_type, base_compression_system_prompt, base_compression_user_prompt) \n",
    "    for file_name, text in file_name_to_original_text.items() for model_type in MODEL_TYPES]\n",
    "\n",
    "model_to_decompressed_text: Dict[str, Dict[str, str]] = defaultdict(dict)\n",
    "decompression_func_args = [\n",
    "    (file_name, text, model_type, base_decompression_system_prompt, base_decompression_user_prompt) \n",
    "    for file_name, text in file_name_to_original_text.items() for model_type in MODEL_TYPES]\n",
    "\n",
    "compression_futures: Dict[cf.Future[str], Tuple[str, str]] = {}\n",
    "with cf.ThreadPoolExecutor(MAX_THREADS) as executor:\n",
    "\n",
    "    while compression_func_args:\n",
    "        for comp_args in compression_func_args:\n",
    "            compression_futures[executor.submit(call_model, *comp_args[1:])] = comp_args\n",
    "\n",
    "        for future in cf.as_completed(compression_futures):\n",
    "            try:\n",
    "                file_name, original_text, model_type = compression_futures.pop(future)\n",
    "                compression_func_args.remove((file_name, original_text, model_type))\n",
    "                compressed_text = future.result()\n",
    "                model_to_compressed_text[model_type][file_name] = compressed_text\n",
    "                logging.info(f'Succesfully compressed: {(file_name, model_type)}')\n",
    "            except Exception as exc:\n",
    "                logging.error(f'Compression generated an exception: {(file_name, model_type)} {exc}')\n",
    "                compression_func_args.append((file_name, original_text, model_type))\n",
    "            finally:\n",
    "                logging.info(f'{len(compression_func_args)} left to compress')\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading text data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text embeddings for each original text\n",
    "file_name_to_original_text_embeddings: Dict[str, np.ndarray] = {}\n",
    "for file_name, original_text in file_name_to_original_text.items():\n",
    "    file_name_to_original_text_embeddings[file_name] = OpenAIHandler.get_text_embedding(original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text embeddings for each decompressed text\n",
    "file_name_to_chatGPT4_decompressed_text_embeddings: Dict[str, np.ndarray] = {}\n",
    "for file_name, decompressed_text in file_name_to_chatGPT4_decompressed_text.items():\n",
    "    file_name_to_chatGPT4_decompressed_text_embeddings[file_name] = OpenAIHandler.get_text_embedding(decompressed_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving GPT-4 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FILE_PATH = \"experiment_data/gpt4_{data_type}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the compressed text\n",
    "GPT4_COMPRESSED_DATA_PATH = BASE_FILE_PATH.format(\"compressed_text\")\n",
    "with open(GPT4_COMPRESSED_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_chatGPT4_compressed_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the decompressed text\n",
    "GPT4_DECOMPRESSED_DATA_PATH = BASE_FILE_PATH.format(\"decompressed_text\")\n",
    "with open(GPT4_DECOMPRESSED_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_chatGPT4_decompressed_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the original text embeddings\n",
    "GPT4_EMBEDDINGS_DATA_PATH = BASE_FILE_PATH.format(\"embeddings\")\n",
    "with open(GPT4_EMBEDDINGS_DATA_PATH, 'w') as f:\n",
    "    json_serializable = {\n",
    "        file_name: embedding.tolist() \n",
    "        for file_name, embedding in file_name_to_original_text_embeddings.items()}\n",
    "    json.dump(json_serializable, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the decompressed text embeddings\n",
    "GPT4_DECOMPRESSED_EMBEDDINGS_DATA_PATH = BASE_FILE_PATH.format(\"decompressed_embeddings\")\n",
    "with open(GPT4_DECOMPRESSED_EMBEDDINGS_DATA_PATH, 'w') as f:\n",
    "    json_serializable = {\n",
    "        file_name: embedding.tolist() \n",
    "        for file_name, embedding in file_name_to_chatGPT4_decompressed_text_embeddings.items()}\n",
    "    json.dump(json_serializable, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Burrows-Wheeler Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_to_zlib_most_compressed_bytes: Dict[str, str] = {}\n",
    "file_name_to_zlib_most_decompressed_text: Dict[str, str] = {}\n",
    "for file_name, original_text in file_name_to_original_text.items():\n",
    "    compressed_bytes = zlib.compress(original_text.encode('utf-8'), level=9)\n",
    "    file_name_to_zlib_most_compressed_bytes[file_name] = compressed_bytes\n",
    "    file_name_to_zlib_most_decompressed_text[file_name] = zlib.decompress(compressed_bytes).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_to_zlib_least_compressed_bytes: Dict[str, str] = {}\n",
    "file_name_to_zlib_least_decompressed_text: Dict[str, str] = {}\n",
    "for file_name, original_text in file_name_to_original_text.items():\n",
    "    compressed_bytes = zlib.compress(original_text.encode('utf-8'), level=1)\n",
    "    file_name_to_zlib_least_compressed_bytes[file_name] = compressed_bytes\n",
    "    file_name_to_zlib_least_decompressed_text[file_name] = zlib.decompress(compressed_bytes).decode('utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_to_chatGPT4_compressed_bytes = {\n",
    "    file_name: compressed_text.encode('utf-8')\n",
    "    for file_name, compressed_text in file_name_to_chatGPT4_compressed_text.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT4 Entropy\n",
    "file_name_to_chatGPT4_compressed_bytes_entropy = {\n",
    "    file_name: functions.entropy(str(compressed_bytes))\n",
    "    for file_name, compressed_bytes in file_name_to_chatGPT4_compressed_bytes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Most Compressed Entropy\n",
    "file_name_to_zlib_most_compressed_bytes_entropy = {\n",
    "    file_name: functions.entropy(str(compressed_bytes))\n",
    "    for file_name, compressed_bytes in file_name_to_zlib_most_compressed_bytes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Most Lease Entropy\n",
    "file_name_to_zlib_least_compressed_bytes_entropy = {\n",
    "    file_name: functions.entropy(str(compressed_bytes))\n",
    "    for file_name, compressed_bytes in file_name_to_zlib_least_compressed_bytes.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Entropy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_MOST_COMPRESSED_DATA_PATH = \"experiment_data/zlib_most_compressed_bytes_entropy_sim.json\"\n",
    "with open(ZLIB_MOST_COMPRESSED_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_most_compressed_bytes_entropy, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_LEAST_COMPRESSED_DATA_PATH = \"experiment_data/zlib_least_compressed_bytes_entropy_sim.json\"\n",
    "with open(ZLIB_LEAST_COMPRESSED_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_least_compressed_bytes_entropy, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph a stacked bar chart of the entropy of the compressed bytes\n",
    "combined_df = pd.DataFrame({\n",
    "    'ChatGPT4': file_name_to_chatGPT4_compressed_bytes_entropy,\n",
    "    'zlib Most Compressed': file_name_to_zlib_most_compressed_bytes_entropy,\n",
    "    'zlib Least Compressed': file_name_to_zlib_least_compressed_bytes_entropy,\n",
    "})\n",
    "\n",
    "# Normalize the data universally, not along the columns\n",
    "combined_df = combined_df / combined_df.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grouped plotly bar chart\n",
    "px.bar(\n",
    "    combined_df, \n",
    "    barmode='group',\n",
    "    title='Relative Entropy of Compressed Bytes',\n",
    "    labels={\n",
    "        'value': 'Entropy',\n",
    "        'index': 'Text',\n",
    "        'variable': 'Compression Method'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average all indeces\n",
    "transposed_df = combined_df.T\n",
    "transposed_df = transposed_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grouped plotly bar chart\n",
    "px.bar(\n",
    "    transposed_df, \n",
    "    x=transposed_df.index,\n",
    "    y=transposed_df.values,\n",
    "    color=transposed_df.index,\n",
    "    text=transposed_df.values.round(3),\n",
    "    title='Averaged Entropy of Compressed Bytes',\n",
    "    labels={\n",
    "        'y': 'Relative Entropy',\n",
    "        'index': 'Compression Method'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Compression Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT Compression Ratio\n",
    "file_name_to_chatGPT4_compression_ratio: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    compression_ratio = 1-(len(file_name_to_chatGPT4_compressed_bytes[file_name]) / len(file_name_to_original_text[file_name].encode('utf-8')))\n",
    "    file_name_to_chatGPT4_compression_ratio[file_name] = compression_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Most Compressed Compression Ratio\n",
    "file_name_to_zlib_most_compression_ratio: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    compression_ratio = 1-(len(file_name_to_zlib_most_compressed_bytes[file_name]) / len(file_name_to_original_text[file_name].encode('utf-8')))\n",
    "    file_name_to_zlib_most_compression_ratio[file_name] = compression_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Most Least Compression Ratio\n",
    "file_name_to_zlib_least_compression_ratio: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    compression_ratio = 1-(len(file_name_to_zlib_least_compressed_bytes[file_name]) / len(file_name_to_original_text[file_name].encode('utf-8')))\n",
    "    file_name_to_zlib_least_compression_ratio[file_name] = compression_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_MOST_COMPRESSION_RATIO_DATA_PATH = \"experiment_data/zlib_most_compression_ratio.json\"\n",
    "with open(ZLIB_MOST_COMPRESSION_RATIO_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_most_compression_ratio, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_LEAST_COMPRESSION_RATIO_DATA_PATH = \"experiment_data/zlib_least_compression_ratio.json\"\n",
    "with open(ZLIB_LEAST_COMPRESSION_RATIO_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_least_compression_ratio, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Compression Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ratio_df = pd.DataFrame({\n",
    "    'ChatGPT4': file_name_to_chatGPT4_compression_ratio,\n",
    "    'zlib Most Compressed': file_name_to_zlib_most_compression_ratio,\n",
    "    'zlib Least Compressed': file_name_to_zlib_least_compression_ratio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the compression ratio\n",
    "px.bar(\n",
    "    combined_ratio_df,\n",
    "    title='Compression Ratio',\n",
    "    labels={\n",
    "        'value': 'Compression Ratio',\n",
    "        'index': 'Text',\n",
    "        'variable': 'Compression Method'},\n",
    "    barmode='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Universly\n",
    "transposed_ratio_df = combined_ratio_df.T\n",
    "transposed_ratio_df = transposed_ratio_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the averaged compression ratio\n",
    "px.bar(\n",
    "    transposed_ratio_df,\n",
    "    x=transposed_ratio_df.index,\n",
    "    y=transposed_ratio_df.values,\n",
    "    color=transposed_ratio_df.index,\n",
    "    text=transposed_ratio_df.values.round(3),\n",
    "    title='Averaged Compression Ratio',\n",
    "    labels={\n",
    "        'value': 'Average Compression Ratio',\n",
    "        'index': 'Compression Method'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT4 Compression Edit Distance\n",
    "file_name_to_chatGPT4_compression_edit_distance: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    compression_edit_distance = functions.edit_distance(file_name_to_chatGPT4_decompressed_text[file_name], file_name_to_original_text[file_name])\n",
    "    file_name_to_chatGPT4_compression_edit_distance[file_name] = compression_edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Most Compressed Compression Edit Distance\n",
    "file_name_to_zlib_most_compression_edit_distance: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    compression_edit_distance = functions.edit_distance(file_name_to_zlib_most_decompressed_text[file_name], file_name_to_original_text[file_name])\n",
    "    file_name_to_zlib_most_compression_edit_distance[file_name] = compression_edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Least Compressed Compression Edit Distance\n",
    "file_name_to_zlib_least_compression_edit_distance: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    compression_edit_distance = functions.edit_distance(file_name_to_zlib_least_decompressed_text[file_name], file_name_to_original_text[file_name])\n",
    "    file_name_to_zlib_least_compression_edit_distance[file_name] = compression_edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_MOST_COMPRESSION_EDIT_DISTANCE_DATA_PATH = \"experiment_data/zlib_most_compression_edit_distance.json\"\n",
    "with open(ZLIB_MOST_COMPRESSION_EDIT_DISTANCE_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_most_compression_edit_distance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_LEAST_COMPRESSION_EDIT_DISTANCE_DATA_PATH = \"experiment_data/zlib_least_compression_edit_distance.json\"\n",
    "with open(ZLIB_LEAST_COMPRESSION_EDIT_DISTANCE_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_least_compression_edit_distance, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_edit_distance_df = pd.DataFrame({\n",
    "    'ChatGPT4': file_name_to_chatGPT4_compression_edit_distance,\n",
    "    'zlib Most Compressed': file_name_to_zlib_most_compression_edit_distance,\n",
    "    'zlib Least Compressed': file_name_to_zlib_least_compression_edit_distance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_edit_distance_df_2 = combined_edit_distance_df.T\n",
    "transposed_edit_distance_df_2 = transposed_edit_distance_df_2.mean(axis=1)\n",
    "# Univerally normalize the data\n",
    "combined_edit_distance_df = combined_edit_distance_df / combined_edit_distance_df.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the compression edit distance\n",
    "px.bar(\n",
    "    combined_edit_distance_df,\n",
    "    title='Compression Edit Distance',\n",
    "    labels={\n",
    "        'value': 'Compression Edit Distance',\n",
    "        'index': 'Text'},\n",
    "    barmode='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Universally\n",
    "transposed_edit_distance_df = combined_edit_distance_df.T\n",
    "transposed_edit_distance_df = transposed_edit_distance_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the compression edit distance\n",
    "px.bar(\n",
    "    transposed_edit_distance_df,\n",
    "    title='Compression Edit Distance',\n",
    "    color=transposed_edit_distance_df.index,\n",
    "    text=transposed_edit_distance_df.values.round(3),\n",
    "    labels={\n",
    "        'value': 'Edit Distance',\n",
    "        'index': 'Compression Method'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Embedding Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT4 Decompression Cosine Similarity\n",
    "file_name_to_chatGPT4_decompression_cosine_similarity: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    decompression_cosine_similarity = functions.cosine_distance(file_name_to_chatGPT4_decompressed_text_embeddings[file_name], file_name_to_original_text_embeddings[file_name])\n",
    "    file_name_to_chatGPT4_decompression_cosine_similarity[file_name] = decompression_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Most Compressed Decompression Cosine Similarity\n",
    "file_name_to_zlib_most_decompression_cosine_similarity: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    # Using the original text embeddings twice as there is no loss in compression\n",
    "    decompression_cosine_similarity = functions.cosine_distance(file_name_to_original_text_embeddings[file_name], file_name_to_original_text_embeddings[file_name])\n",
    "    file_name_to_zlib_most_decompression_cosine_similarity[file_name] = decompression_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlib Leasr Compressed Decompression Cosine Similarity\n",
    "file_name_to_zlib_least_decompression_cosine_similarity: Dict[str, float] = {}\n",
    "for file_name in file_name_to_original_text.keys():\n",
    "    # Using the original text embeddings twice as there is no loss in compression\n",
    "    decompression_cosine_similarity = functions.cosine_distance(file_name_to_original_text_embeddings[file_name], file_name_to_original_text_embeddings[file_name])\n",
    "    file_name_to_zlib_least_decompression_cosine_similarity[file_name] = decompression_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_MOST_COMPRESSION_COSINE_SIM_DATA_PATH = \"experiment_data/zlib_most_cosine_sim.json\"\n",
    "with open(ZLIB_MOST_COMPRESSION_COSINE_SIM_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_most_decompression_cosine_similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_LEAST_COMPRESSION_COSINE_SIM_DATA_PATH = \"experiment_data/zlib_least_cosine_sim.json\"\n",
    "with open(ZLIB_LEAST_COMPRESSION_COSINE_SIM_DATA_PATH, 'w') as f:\n",
    "    json.dump(file_name_to_zlib_least_decompression_cosine_similarity, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Embedding Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cosine_similarity_df = pd.DataFrame({\n",
    "    'ChatGPT4': file_name_to_chatGPT4_decompression_cosine_similarity,\n",
    "    'zlib Most Compressed': file_name_to_zlib_most_decompression_cosine_similarity,\n",
    "    'zlib Least Compressed': file_name_to_zlib_least_decompression_cosine_similarity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decompression cosine similarity\n",
    "px.bar(\n",
    "    combined_cosine_similarity_df,\n",
    "    title='Decompression Embedding Cosine Similarity',\n",
    "    labels={\n",
    "        'value': 'Cosine Similarity',\n",
    "        'index': 'Text'},\n",
    "    barmode='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Universally\n",
    "transposed_cosine_similarity_df = combined_cosine_similarity_df.T\n",
    "transposed_cosine_similarity_df = transposed_cosine_similarity_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decompression cosine similarity\n",
    "px.bar(\n",
    "    transposed_cosine_similarity_df,\n",
    "    title='Averaged Decompression Cosine Similarity',\n",
    "    color=transposed_cosine_similarity_df.index,\n",
    "    text=transposed_cosine_similarity_df.values.round(3),\n",
    "    labels={\n",
    "        'value': 'Decompression Cosine Similarity',\n",
    "        'index': 'Compression Method'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
